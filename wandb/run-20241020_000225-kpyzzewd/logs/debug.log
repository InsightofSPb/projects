2024-10-20 00:02:25,758 INFO    MainThread:137761 [wandb_setup.py:_flush():68] Configure stats pid to 137761
2024-10-20 00:02:25,758 INFO    MainThread:137761 [wandb_setup.py:_flush():68] Loading settings from /home/sasha/.config/wandb/settings
2024-10-20 00:02:25,758 INFO    MainThread:137761 [wandb_setup.py:_flush():68] Loading settings from /home/sasha/segment_barcode/wandb/settings
2024-10-20 00:02:25,758 INFO    MainThread:137761 [wandb_setup.py:_flush():68] Loading settings from environment variables: {'_require_service': 'True'}
2024-10-20 00:02:25,758 INFO    MainThread:137761 [wandb_setup.py:_flush():68] Inferring run settings from compute environment: {'program_relpath': 'train.py', 'program': '/home/sasha/segment_barcode/train.py'}
2024-10-20 00:02:25,758 INFO    MainThread:137761 [wandb_init.py:_log_setup():476] Logging user logs to ./wandb/run-20241020_000225-kpyzzewd/logs/debug.log
2024-10-20 00:02:25,759 INFO    MainThread:137761 [wandb_init.py:_log_setup():477] Logging internal logs to ./wandb/run-20241020_000225-kpyzzewd/logs/debug-internal.log
2024-10-20 00:02:25,759 INFO    MainThread:137761 [wandb_init.py:init():516] calling init triggers
2024-10-20 00:02:25,759 INFO    MainThread:137761 [wandb_init.py:init():519] wandb.init called with sweep_config: {}
config: {'project_name': 'barcode_segmentation', 'experiment_name': 'first try', 'training_settings': {'batch_size': 8, 'n_workers': 4, 'train_test_split': 0.6, 'img_h': 256, 'img_w': 1600, 'random_seed': 42}, 'n_epochs': 20, 'accelerator': 'gpu', 'device': 0, 'optimizer': 'Adam', 'optimizer_param': {'lr': 0.001, 'weight_decay': 0.0001}, 'scheduler': 'ReduceLROnPlateau', 'scheduler_param': {'factor': 0.8, 'patience': 2, 'min_lr': 1e-06}, 'cls_losses': [{'alias': 'bce', 'weight': 0.3, 'loss_fn': 'torch.nn.BCEWithLogitsLoss', 'loss_kwargs': {}}], 'seg_losses': [{'alias': 'focal', 'weight': 0.3, 'loss_fn': 'segmentation_models_pytorch.losses.FocalLoss', 'loss_kwargs': {'mode': 'binary'}}, {'alias': 'dice', 'weight': 0.4, 'loss_fn': 'segmentation_models_pytorch.losses.DiceLoss', 'loss_kwargs': {'mode': 'binary', 'from_logits': True}}], 'monitor_metric': 'val_iou', 'monitor_mode': 'max'}
2024-10-20 00:02:25,759 INFO    MainThread:137761 [wandb_init.py:init():569] starting backend
2024-10-20 00:02:25,759 INFO    MainThread:137761 [wandb_init.py:init():573] setting up manager
2024-10-20 00:02:25,763 INFO    MainThread:137761 [backend.py:_multiprocessing_setup():102] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-10-20 00:02:25,765 INFO    MainThread:137761 [wandb_init.py:init():580] backend started and connected
2024-10-20 00:02:25,768 INFO    MainThread:137761 [wandb_init.py:init():658] updated telemetry
2024-10-20 00:02:25,773 INFO    MainThread:137761 [wandb_init.py:init():693] communicating run to backend with 60 second timeout
2024-10-20 00:02:26,442 INFO    MainThread:137761 [wandb_run.py:_on_init():2006] communicating current version
2024-10-20 00:02:26,620 INFO    MainThread:137761 [wandb_run.py:_on_init():2010] got version response upgrade_message: "wandb version 0.18.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2024-10-20 00:02:26,621 INFO    MainThread:137761 [wandb_init.py:init():728] starting run threads in backend
2024-10-20 00:02:26,746 INFO    MainThread:137761 [wandb_run.py:_console_start():1986] atexit reg
2024-10-20 00:02:26,746 INFO    MainThread:137761 [wandb_run.py:_redirect():1844] redirect: SettingsConsole.WRAP_RAW
2024-10-20 00:02:26,746 INFO    MainThread:137761 [wandb_run.py:_redirect():1909] Wrapping output streams.
2024-10-20 00:02:26,746 INFO    MainThread:137761 [wandb_run.py:_redirect():1931] Redirects installed.
2024-10-20 00:02:26,747 INFO    MainThread:137761 [wandb_init.py:init():765] run started, returning control to user process
2024-10-20 00:02:31,816 WARNING MsgRouterThr:137761 [router.py:message_loop():77] message_loop has been closed
