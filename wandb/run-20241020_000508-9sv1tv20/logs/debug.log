2024-10-20 00:05:08,568 INFO    MainThread:139468 [wandb_setup.py:_flush():68] Configure stats pid to 139468
2024-10-20 00:05:08,568 INFO    MainThread:139468 [wandb_setup.py:_flush():68] Loading settings from /home/sasha/.config/wandb/settings
2024-10-20 00:05:08,568 INFO    MainThread:139468 [wandb_setup.py:_flush():68] Loading settings from /home/sasha/segment_barcode/wandb/settings
2024-10-20 00:05:08,568 INFO    MainThread:139468 [wandb_setup.py:_flush():68] Loading settings from environment variables: {'_require_service': 'True'}
2024-10-20 00:05:08,568 INFO    MainThread:139468 [wandb_setup.py:_flush():68] Inferring run settings from compute environment: {'program_relpath': 'train.py', 'program': '/home/sasha/segment_barcode/train.py'}
2024-10-20 00:05:08,568 INFO    MainThread:139468 [wandb_init.py:_log_setup():476] Logging user logs to ./wandb/run-20241020_000508-9sv1tv20/logs/debug.log
2024-10-20 00:05:08,568 INFO    MainThread:139468 [wandb_init.py:_log_setup():477] Logging internal logs to ./wandb/run-20241020_000508-9sv1tv20/logs/debug-internal.log
2024-10-20 00:05:08,569 INFO    MainThread:139468 [wandb_init.py:init():516] calling init triggers
2024-10-20 00:05:08,569 INFO    MainThread:139468 [wandb_init.py:init():519] wandb.init called with sweep_config: {}
config: {'project_name': 'barcode_segmentation', 'experiment_name': 'first try', 'training_settings': {'batch_size': 8, 'n_workers': 4, 'train_test_split': 0.6, 'img_h': 256, 'img_w': 1600, 'random_seed': 42}, 'n_epochs': 20, 'accelerator': 'gpu', 'device': 0, 'optimizer': 'Adam', 'optimizer_param': {'lr': 0.001, 'weight_decay': 0.0001}, 'scheduler': 'ReduceLROnPlateau', 'scheduler_param': {'factor': 0.8, 'patience': 2, 'min_lr': 1e-06}, 'cls_losses': [{'alias': 'bce', 'weight': 0.3, 'loss_fn': 'torch.nn.BCEWithLogitsLoss', 'loss_kwargs': {}}], 'seg_losses': [{'alias': 'focal', 'weight': 0.3, 'loss_fn': 'segmentation_models_pytorch.losses.FocalLoss', 'loss_kwargs': {'mode': 'binary'}}, {'alias': 'dice', 'weight': 0.4, 'loss_fn': 'segmentation_models_pytorch.losses.DiceLoss', 'loss_kwargs': {'mode': 'binary', 'from_logits': True}}], 'monitor_metric': 'val_iou', 'monitor_mode': 'max'}
2024-10-20 00:05:08,569 INFO    MainThread:139468 [wandb_init.py:init():569] starting backend
2024-10-20 00:05:08,569 INFO    MainThread:139468 [wandb_init.py:init():573] setting up manager
2024-10-20 00:05:08,570 INFO    MainThread:139468 [backend.py:_multiprocessing_setup():102] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-10-20 00:05:08,571 INFO    MainThread:139468 [wandb_init.py:init():580] backend started and connected
2024-10-20 00:05:08,573 INFO    MainThread:139468 [wandb_init.py:init():658] updated telemetry
2024-10-20 00:05:08,577 INFO    MainThread:139468 [wandb_init.py:init():693] communicating run to backend with 60 second timeout
2024-10-20 00:05:09,275 INFO    MainThread:139468 [wandb_run.py:_on_init():2006] communicating current version
2024-10-20 00:05:09,444 INFO    MainThread:139468 [wandb_run.py:_on_init():2010] got version response upgrade_message: "wandb version 0.18.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2024-10-20 00:05:09,444 INFO    MainThread:139468 [wandb_init.py:init():728] starting run threads in backend
2024-10-20 00:05:09,565 INFO    MainThread:139468 [wandb_run.py:_console_start():1986] atexit reg
2024-10-20 00:05:09,565 INFO    MainThread:139468 [wandb_run.py:_redirect():1844] redirect: SettingsConsole.WRAP_RAW
2024-10-20 00:05:09,566 INFO    MainThread:139468 [wandb_run.py:_redirect():1909] Wrapping output streams.
2024-10-20 00:05:09,566 INFO    MainThread:139468 [wandb_run.py:_redirect():1931] Redirects installed.
2024-10-20 00:05:09,566 INFO    MainThread:139468 [wandb_init.py:init():765] run started, returning control to user process
2024-10-20 00:05:10,362 INFO    MainThread:139468 [wandb_run.py:_config_callback():1163] config_cb None None {'project_name': 'barcode_segmentation', 'experiment_name': 'first try', 'training_settings/batch_size': 8, 'training_settings/n_workers': 4, 'training_settings/train_test_split': 0.6, 'training_settings/img_h': 256, 'training_settings/img_w': 1600, 'training_settings/random_seed': 42, 'n_epochs': 20, 'accelerator': 'gpu', 'device': 0, 'optimizer': 'Adam', 'optimizer_param/lr': 0.001, 'optimizer_param/weight_decay': 0.0001, 'scheduler': 'ReduceLROnPlateau', 'scheduler_param/factor': 0.8, 'scheduler_param/patience': 2, 'scheduler_param/min_lr': 1e-06, 'cls_losses': [{'alias': 'bce', 'weight': 0.3, 'loss_fn': 'torch.nn.BCEWithLogitsLoss', 'loss_kwargs': {}}], 'seg_losses': [{'alias': 'focal', 'weight': 0.3, 'loss_fn': 'segmentation_models_pytorch.losses.FocalLoss', 'loss_kwargs': {'mode': 'binary'}}, {'alias': 'dice', 'weight': 0.4, 'loss_fn': 'segmentation_models_pytorch.losses.DiceLoss', 'loss_kwargs': {'mode': 'binary', 'from_logits': True}}], 'monitor_metric': 'val_iou', 'monitor_mode': 'max'}
2024-10-20 00:05:16,067 WARNING MsgRouterThr:139468 [router.py:message_loop():77] message_loop has been closed
